{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from PIL import Image as pilimg\nimport numpy as np\nimport os\nimport time\nimport cv2\nimport torch\nimport torchvision\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.mobile_optimizer import optimize_for_mobile\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_SIZE = 224\nNUM_CLASSES= 14\nIMAGE_SHAPE = [224,224]\nmean = [0.5, 0.5, 0.5]\nstd = [0.5, 0.5, 0.5]\ntrain_loss_hist = []\nval_loss_hist = []","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Defining Functions","metadata":{}},{"cell_type":"code","source":"def load_images_from_folder(folder,i): #Couldn't use common image loaders due to diversity of extensions\n    image = []\n    image_y= []\n    for filename in os.listdir(folder):\n        img = cv2.imread(os.path.join(folder,filename))\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        if img is not None:\n            img = cv2.resize(img,(IMG_SIZE,IMG_SIZE))\n            img = img.reshape(IMG_SIZE,IMG_SIZE,3)\n            image.append(img)\n            image_y.append(i)\n    return image,image_y","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model, criterion, optimizer, num_epochs=25):\n   since = time.time()\n\n   for epoch in range(num_epochs):\n       print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n       print('-' * 10)\n\n       #set model to trainable\n       # model.train()\n\n       train_loss = 0\n       tot_val_loss = 0\n       # Iterate over data.\n       for i, data in enumerate(dataloaders['train']):\n           inputs , labels = data\n           inputs = inputs.to(device)\n           labels = labels.to(device)\n          \n           optimizer.zero_grad()\n          \n           with torch.set_grad_enabled(True):\n               outputs  = model(inputs)\n               loss = criterion(outputs, labels)\n           \n               \n           \n           loss.backward() # calculates grads of all trainable parameter\n           optimizer.step() #updates parameters\n\n           train_loss += loss.item() * inputs.size(0)\n           print('{} Loss: {:.4f} '.format(\n               'train', train_loss / dataset_sizes['train']))\n       train_loss_hist.append(train_loss / dataset_sizes['train'])\n           \n           \n       for i, val_data in enumerate(dataloaders['validation']):\n           val_inputs , val_labels = val_data\n           val_inputs = val_inputs.to(device)\n           val_labels = val_labels.to(device)\n           optimizer.zero_grad()\n           with torch.set_grad_enabled(True):\n               val_outputs  = model(val_inputs)\n               val_loss= criterion(val_outputs, val_labels)\n           val_loss.backward()\n           tot_val_loss += val_loss.item() * val_inputs.size(0)\n       val_loss_hist.append(tot_val_loss / dataset_sizes['validation'])\n       print('{} Loss: {:.4f} '.format('validation', tot_val_loss / dataset_sizes['validation']))\n          \n   time_elapsed = time.time() - since\n   print('Training complete in {:.0f}m {:.0f}s'.format(\n       time_elapsed // 60, time_elapsed % 60))\n   lst_iter = range(num_epochs)\n   plt.plot(lst_iter, train_loss_hist, '-b', label='train_loss')\n   plt.plot(lst_iter, val_loss_hist, '-r', label='val_loss')\n   plt.xlabel(\"n iteration\")\n   plt.legend(loc='upper left')\n\n   return model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_model(model, num_images=6):\n   was_training = model.training\n   model.eval()\n   images_so_far = 0\n\n   with torch.no_grad():\n       for i, (inputs, labels) in enumerate(dataloaders['validation']):\n           inputs = inputs.to(device)\n           labels = labels.to(device)\n\n           outputs = model(inputs)\n           _, preds = torch.max(outputs, 1)\n\n           for j in range(inputs.size()[0]):\n               images_so_far += 1\n               ax = plt.subplot(num_images//2, 2, images_so_far)\n               ax.axis('off')\n               ax.set_title('predicted: {} truth: {}'.format(class_names[preds[j]], class_names[labels[j]]))\n               img = inputs.cpu().data[j].numpy().transpose((1, 2, 0))\n               img = std * img + mean\n               ax.imshow(img)\n\n               if images_so_far == num_images:\n                   model.train(mode=was_training)\n                   return\n       model.train(mode=was_training)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Main Code","metadata":{}},{"cell_type":"code","source":"labels = [\"basking\", \"blacktip\", \"blue\", \"bull\", \"hammerhead\", \"lemon\",\"mako\", \"nurse\", \"sandtiger\", \"thresher\",\"tiger\", \"whale\", \"white\", \"whitetip\"]\nX = np.empty((0,IMG_SIZE,IMG_SIZE,3))\ny = np.empty((0,1))\nfor i in range(len(labels)):\n    images, images_y = load_images_from_folder(r\"sharks/\"+labels[i],i)\n    X = np.append(X,images,0)\n    y = np.append(y,images_y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(X_train)): #Numpy arrays converted back to files to save in DataLoader as JPEG\n    im = pilimg.fromarray(X_train[i].astype(\"uint8\"))\n    im.save(f'sharks_final/train/{labels[int(y_train[i])]}/{i}.png', \"JPEG\")\nfor i in range(len(X_test)):\n    im = pilimg.fromarray(X_test[i].astype(\"uint8\"))\n    im.save(f'sharks_final/validation/{labels[int(y_test[i])]}/{i}.png', \"JPEG\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_transforms = {\n   'train': transforms.Compose([\n       transforms.CenterCrop(IMG_SIZE),\n       transforms.RandomHorizontalFlip(0.5), #augmentation\n       transforms.RandomCrop(IMG_SIZE, pad_if_needed= True),\n       transforms.RandomPerspective(p=0.5),\n       transforms.ColorJitter(brightness=1, contrast=1, saturation=1),\n       transforms.ToTensor(),\n       transforms.Normalize(mean, std)\n   ]),\n   'validation': transforms.Compose([\n       transforms.CenterCrop(IMG_SIZE),\n       transforms.ToTensor(),\n       transforms.Normalize(mean, std)\n       ]),\n    }\n    \n    image_datasets = {\n       x: datasets.ImageFolder(\n           \"sharks_final/\"+x,\n           transform=data_transforms[x]\n       )\n       for x in ['train', 'validation']\n    }\n    \n    dataloaders = {\n       x: torch.utils.data.DataLoader(\n           image_datasets[x], batch_size=16,\n           shuffle=True, num_workers=4\n       )\n       for x in ['train', 'validation']\n    }\n    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'validation']}\n    print(dataset_sizes)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = image_datasets['train'].classes\n    print(class_names)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mobilenet = torchvision.models.mobilenet_v3_small(pretrained=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for param in  mobilenet.parameters():\n        param.requires_grad = False","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"number_infeatures = mobilenet.classifier[3].in_features\nfeatures = list(mobilenet.classifier.children())[:-1] # Removes last layer\nfeatures.extend([torch.nn.Linear(number_infeatures, len(class_names))])\nmobilenet.classifier = torch.nn.Sequential(*features)\n\nmobilenet = mobilenet.to(device)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = torch.nn.CrossEntropyLoss() #defining loss function\noptimizer_ft = optim.SGD(mobilenet.parameters(), lr=0.001, momentum=0.9) #defining optimizer\nmobilenet = train_model(mobilenet, criterion, optimizer_ft, num_epochs=30) #training the model\n\nvisualize_model(mobilenet)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Saving Model for Mobile Apllication","metadata":{}},{"cell_type":"code","source":"quantized_model = torch.quantization.convert(mobilenet)\nexample = torch.rand(1,3,224,224)\nscripted_model = torch.jit.trace(quantized_model, example)\nopt_model = optimize_for_mobile(scripted_model)\nopt_model._save_for_lite_interpreter(\"model_output/MobileNetV3.ptl\")","metadata":{},"execution_count":null,"outputs":[]}]}